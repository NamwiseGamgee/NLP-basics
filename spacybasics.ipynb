{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd8e267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965aab60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model as nlp\n",
    "nlp = spacy.load('en_core_web_sm') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09cce349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#created an object named doc by applying the model to our text\n",
    "#here, this doc object will hold the processed texts\n",
    "#unicode string starts with u''.. This will parse this sentence into tokens\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea0122d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is VERB aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "#pos means parts of speech.. token.pos gives a number corresponding to that pos\n",
    "#token.pos_ gives the exact name of the parts of speech\n",
    "#token.dep_ gives the syntactic dependency of the parts of speech\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95034cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I PRON nsubj\n",
      "do VERB aux\n",
      "not ADV neg\n",
      "feel VERB ROOT\n",
      "like ADP prep\n",
      "going VERB pcomp\n",
      "out PART prt\n",
      "today NOUN npadvmod\n",
      ". PUNCT punct\n",
      "I PRON nsubj\n",
      "am VERB ROOT\n",
      "very ADV advmod\n",
      "busy ADJ acomp\n",
      "learning VERB xcomp\n",
      "spacy ADJ dobj\n"
     ]
    }
   ],
   "source": [
    "my_sent = nlp(u'I do not feel like going out today. I am very busy learning spacy')\n",
    "for token in my_sent:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6eca75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x2c1eb69a348>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x2c1eb8930a8>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x2c1eb893648>)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline #to see the basic nlp pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e47f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names #to see the attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8467bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first step to process any text is tokenization (split it up- words and punctuations into tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "585bd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't        looking into startup anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c52bad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla tesla PROPN nsubj\n",
      "is be VERB aux\n",
      "n't not ADV neg\n",
      "                SPACE \n",
      "looking look VERB ROOT\n",
      "into into ADP prep\n",
      "startup startup NOUN pobj\n",
      "anymore anymore ADV advmod\n",
      ". . PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "#token.lemma_ gives you the base form of the word\n",
    "for token in doc2:\n",
    "    print(token.text, token.lemma_, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c407f0c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can get any index token from the doc2 now\n",
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "019ebfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06b71863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "#a span is a slice of a large doc doc[start:end]\n",
    "life_quote = doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ebd6bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f63da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"This is the first sentence. This is another sentence. This is the last sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36781a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence\n"
     ]
    }
   ],
   "source": [
    "#doc.sents splits up sentences. spacy is smart enough to seperate sentences\n",
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e752d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6]#.is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9c375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
