{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d14a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04af52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa4a067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69b15172",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cffa9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we want to detect stuff with the matcher object. detect different patterns. \n",
    "#here we want to detect/match any patterns of solarpower written in the 3 formats shown\n",
    "#SolarPower\n",
    "#Solar-power\n",
    "#Solar power\n",
    "\n",
    "pattern1 = [{'LOWER':'solarpower'}] #solarpower\n",
    "\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{'LOWER':'power'}] #solar-power\n",
    "\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}] #Solar power\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f131609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to add the pattens to the matcher function\n",
    "#matcher('name',callback,pattern1,2,3)\n",
    "matcher.add('SolarPower',None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15c731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The Solar Power industry continues to grow as solarpower increases. Solar-power is amazing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc29bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the matches.. take the doc and pass it to the matcher object\n",
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c58c5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9), (8656102463236116519, 11, 14)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34758ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 8 9 solarpower\n",
      "8656102463236116519 SolarPower 11 14 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] #get string representation\n",
    "    span = doc[start:end]  #get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84d0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cabf4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove a particular pattern from the matcher\n",
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a60873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e998a173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding new pattern to the matcher\n",
    "#this 'OP':'*' matches any punctuation that occurs zero, one or more times i.e. -- or ,,\n",
    "\n",
    "#solarpower\n",
    "pattern1 = [{'LOWER':'solarpower'}]\n",
    "\n",
    "#solar.power, solar-power, solar--power, solar---power etc\n",
    "pattern2 = [{'LOWER':'solar'},{'IS_PUNCT': True, 'OP':'*'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be6a104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower',None, pattern1,pattern2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "72a4ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Solar--power is solarpower yay! But solar:power is also solar---power!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86a08123",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "697f4c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(13798162653491708028, 0, 3), (8656102463236116519, 0, 3), (13798162653491708028, 4, 5), (8656102463236116519, 4, 5), (13798162653491708028, 8, 11), (8656102463236116519, 8, 11), (13798162653491708028, 13, 16), (8656102463236116519, 13, 16)]\n"
     ]
    }
   ],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccf6d0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13798162653491708028 SolarPowe 0 3 Solar--power\n",
      "8656102463236116519 SolarPower 0 3 Solar--power\n",
      "13798162653491708028 SolarPowe 4 5 solarpower\n",
      "8656102463236116519 SolarPower 4 5 solarpower\n",
      "13798162653491708028 SolarPowe 8 11 solar:power\n",
      "8656102463236116519 SolarPower 8 11 solar:power\n",
      "13798162653491708028 SolarPowe 13 16 solar---power\n",
      "8656102463236116519 SolarPower 13 16 solar---power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] #get string representation\n",
    "    span = doc2[start:end]  #get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f229a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching on a terminalogy list is more efficient than pattern matching\n",
    "#therefore will will use a phrase matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602cb5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f0ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7428695",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"F:\\\\NLP intro\\\\course stuff\\\\UPDATED_NLP_COURSE\\\\TextFiles\\\\reaganomics.txt\") as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fe05e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets create the phrases we want to look for\n",
    "phrase_list = ['voodoo economics','supply-side economics','trickle-down economics','free-market economics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb350622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we will convert each phrase into a document object\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1e4ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[voodoo economics,\n",
       " supply-side economics,\n",
       " trickle-down economics,\n",
       " free-market economics]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "815bfc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then pass each doc object into a matcher\n",
    "#*phrase_patterns is a shorthand for phrase_patterns[0], ph_pat[1], ph_p[2] etc\n",
    "matcher.add('EconMatcher',None,*phrase_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6edf8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61c4594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3680293220734633682, 41, 45),\n",
       " (3680293220734633682, 49, 53),\n",
       " (3680293220734633682, 54, 56),\n",
       " (3680293220734633682, 61, 65),\n",
       " (3680293220734633682, 673, 677),\n",
       " (3680293220734633682, 2985, 2989)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a88208e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 supply-side economics\n",
      "3680293220734633682 EconMatcher 49 53 trickle-down economics\n",
      "3680293220734633682 EconMatcher 54 56 voodoo economics\n",
      "3680293220734633682 EconMatcher 61 65 free-market economics\n",
      "3680293220734633682 EconMatcher 673 677 supply-side economics\n",
      "3680293220734633682 EconMatcher 2985 2989 trickle-down economics\n"
     ]
    }
   ],
   "source": [
    "#to view the matches\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] #get string representation\n",
    "    span = doc3[start:end]  #get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd59a4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to get some context on which these terms were used, we will have to\n",
    "#get a bit more of a token span.. maybe +5 more tokens after end and -5 before start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7c37fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3680293220734633682 EconMatcher 41 45 policies are commonly associated with supply-side economics, referred to as trickle\n",
      "3680293220734633682 EconMatcher 49 53 economics, referred to as trickle-down economics or voodoo economics by political\n",
      "3680293220734633682 EconMatcher 54 56 trickle-down economics or voodoo economics by political opponents, and\n",
      "3680293220734633682 EconMatcher 61 65 by political opponents, and free-market economics by political advocates.\n",
      "\n",
      "\n",
      "3680293220734633682 EconMatcher 673 677 attracted a following from the supply-side economics movement, which formed in\n",
      "3680293220734633682 EconMatcher 2985 2989 became widely known as \"trickle-down economics\", due to the\n"
     ]
    }
   ],
   "source": [
    "#to get some context\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id] #get string representation\n",
    "    span = doc3[start-5:end+5]  #get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89cc029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step by step.. How to find a matching pattern or name or look for something in a doc using spacy\n",
    "#1 import Matcher from spacy.matcher\n",
    "#2 create a my_matcher object.. Pass in the nlp.vocab library in the imported Matcher\n",
    "#3 define your patterns... The ones you want to find\n",
    "#4 add the patterns into your my_matcher object\n",
    "#5 open the txt that you want to seach for patterns in and create an nlp doc using the whole txt file\n",
    "#6 get the matches found by passing the nlp doc into your my_matcher\n",
    "#7 print the matches.. maybe print a bit more tokens for some context rather than only the match itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5390a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8d184db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "my_matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dc2bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "pattern1 = [{'LOWER':'lionel'},{'LOWER':'messi'}]\n",
    "pattern2 = [{'LOWER':'iniesta'}]\n",
    "pattern3 = [{'LOWER':'forlan'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "571942cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "my_matcher.add('wclegends',None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e24ffe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "with open(\"F:\\\\NLP intro\\\\course stuff\\\\UPDATED_NLP_COURSE\\\\TextFiles\\\\fifawc2010.txt\") as f:\n",
    "    wcDoc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61eaf97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "found_matches = my_matcher(wcDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19591406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8170561629599831063, 120, 121),\n",
       " (8170561629599831063, 192, 194),\n",
       " (8170561629599831063, 225, 226)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0906c692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8170561629599831063 wclegends 120 121 midfield maestro AndrÃ©s Iniesta etched his name in history\n",
      "8170561629599831063 wclegends 192 194 the quarterfinals against Uruguay. Lionel Messi, although not as prolific\n",
      "8170561629599831063 wclegends 225 226 for players like ForlÃ¡n, Iniesta, and MÃ¼ller to shine\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = wcDoc[start-5:end+5]\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a74b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
